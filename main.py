from pprint import pprint
from pickle import dump, load
from os.path import exists
from json import dump as json_dump
from requests import get
from collections import Counter
from bs4 import BeautifulSoup

from area import get_area_id
from skills import get_skills

vacancy = 'linux'  # –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∞—è –≤–∞–∫–∞–Ω—Å–∏—è
my_city = '–ú–æ—Å–∫–≤–∞' # –≥–æ—Ä–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ (all - –¥–ª—è –≤—Å–µ—Ö)
url = 'https://api.hh.ru/vacancies'

# –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—É—â–∏—Ö –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç –¶–ë –†–§
data = get('https://www.cbr-xml-daily.ru/daily_json.js').json()
rate = data['Valute']

# –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –∫–æ–¥–∞–º–∏ –≥–æ—Ä–æ–¥–æ–≤
if exists('area.pkl'):
    with open('area.pkl', mode='rb') as f:
        area = load(f)
else:
    area = {}

print('\n ===== –ö–û–î–´ –ì–û–†–û–î–û–í =====')
pprint(area)

p = {'text': vacancy}
r = get(url=url, params=p).json()
count_pages = r['pages']
all_count = len(r['items'])

result = {
        'keywords': vacancy,
        'count': all_count,
        'city': my_city
         }

sal = {'from': [], 'to': []}
skills_all = []

# –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç –ø–æ–ª—É—á–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü, –∏ –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–π –∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü
print(f'\nüåê –ü–µ—Ä–µ–±–æ—Ä 5 —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ {count_pages} –Ω–∞ —Ä–µ—Å—É—Ä—Å–µ: {url}')
for page in range(count_pages):
    if page > 4:
        break
    else:
        print(f'üëÄ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {page+1}')
    p = {'text': vacancy,
         'page': page}
    ress = get(url=url, params=p).json()
    all_count = len(ress['items'])
    result['count'] += all_count
    
    city_count = 0
    for res in ress['items']:
        city_vac = res['area']['name']
        # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å–∞, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ —Ñ–∞–π–ª–µ
        if city_vac not in area:
            area[city_vac] = get_area_id(res['area']['id'])
        
        if my_city == 'all' or city_vac == my_city:
            city_count += 1
            res_full = get(res['url']).json()
            skills = get_skills(res_full['description'], res_full['key_skills'])
            skills_all += skills
        
            # –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã
            if res_full['salary']:
                code = res_full['salary']['currency']
                #print(f'[{code}]')
                k = 1 if code == 'RUR' else float(rate[code]['Value'])
                sal['from'].append(k * res_full['salary']['from'] if res['salary']['from'] else k * res_full['salary']['to'])
                sal['to'].append(k * res_full['salary']['to'] if res['salary']['to'] else k*res_full['salary']['from'])

# —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
result.update({
    'city_count': city_count,
    'average_from': round(sum(sal['from']) / len(sal['from']), 2),
    'average_to': round(sum(sal['to']) / len(sal['to']), 2),
    'requirements': [{'name': name, 'count': count, 'percent': round((count / result['count'])*100, 2)} 
                      for name, count in Counter(skills_all).most_common(5)]
})

print(f'\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–∞–∫–∞–Ω—Å–∏–∏ [{vacancy}] –≤ –≥–æ—Ä–æ–¥–µ {my_city}:\n')
pprint(result, sort_dicts=False)

# —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞–º–∏ —Ä–∞–±–æ—Ç—ã
with open('result.json', mode='w') as f:
    json_dump([result], f)
with open('area.pkl', mode='wb') as f:
    dump(area, f)
